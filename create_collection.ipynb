{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta, date\n",
    "from zipfile import ZipFile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib\n",
    "import glob \n",
    "# import viz \n",
    "import os \n",
    "\n",
    "end_date = datetime.today() - timedelta(days=2)\n",
    "start_date = end_date - timedelta(days= 7)\n",
    "merged_data = []\n",
    "time = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "from zipfile import ZipFile\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def gen_dates(input_date):\n",
    "    try:\n",
    "        # Parse the input date string into a datetime object\n",
    "        input_date = datetime.strptime(input_date, \"%d/%m/%Y\")\n",
    "        \n",
    "        # Initialize lists to store past and succeeding 15 days\n",
    "        past_dates = []\n",
    "        succeeding_dates = []\n",
    "\n",
    "        # Generate past dates\n",
    "        for i in range(15, 0, -1):\n",
    "            past_date = input_date - timedelta(days=i)\n",
    "            past_dates.append(past_date.strftime(\"%Y%m%d\"))  # Format as yyyymmdd\n",
    "\n",
    "        # Generate succeeding dates\n",
    "        for i in range(1, 16):\n",
    "            succeeding_date = input_date + timedelta(days=i)\n",
    "            succeeding_dates.append(succeeding_date.strftime(\"%Y%m%d\"))  # Format as yyyymmdd\n",
    "\n",
    "        return past_dates, succeeding_dates\n",
    "    except ValueError:\n",
    "        # Handle the case when the input date is not in the correct format\n",
    "        return [], []\n",
    "\n",
    "def download_and_filter_gdelt_data(output_file_path, input_date, locations_regex, themes_regex):\n",
    "    try:\n",
    "        # Generate the date range using the input date\n",
    "        past_dates, succeeding_dates = gen_dates(input_date)\n",
    "\n",
    "        # Set the directory where the script is located as the working directory\n",
    "        script_directory = os.path.dirname(os.path.abspath(__file__))\n",
    "        os.chdir(script_directory)\n",
    "\n",
    "        # Create an empty list to store the merged data\n",
    "        merged_data = []\n",
    "\n",
    "        # Download, filter, and save GDELT data\n",
    "        for day in past_dates + succeeding_dates:\n",
    "            day_str = day.replace(\"/\", \"\")\n",
    "            url = \"http://data.gdeltproject.org/gkg/\" + day_str + \".gkg.csv.zip\"\n",
    "            file_name = f\"GEvents1_{day_str}.zip\"\n",
    "\n",
    "            # Download the file\n",
    "            urllib.request.urlretrieve(url, file_name)\n",
    "            print(\"Downloaded \" + file_name)\n",
    "\n",
    "            # Extract the file\n",
    "            with ZipFile(file_name, \"r\") as zipObj:\n",
    "                zipObj.extractall()\n",
    "            os.remove(file_name)\n",
    "\n",
    "            # Construct the full path to the CSV file\n",
    "            csv_file_name = os.path.join(script_directory, f\"gkg.{day_str}.gkg.csv\")\n",
    "\n",
    "            # Check if the CSV file exists\n",
    "            if not os.path.exists(csv_file_name):\n",
    "                print(f\"CSV file {csv_file_name} not found for {day_str}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Load the CSV data into a pandas DataFrame\n",
    "            df = pd.read_csv(csv_file_name, delimiter=\"\\t\")\n",
    "\n",
    "            # Apply optional filters for locations and themes using contains and regex\n",
    "            if locations_regex is not None:\n",
    "                df = df[df['LOCATIONS'].str.contains(locations_regex, case=False, na=False, regex=True)]\n",
    "\n",
    "            if themes_regex is not None:\n",
    "                df = df[df['THEMES'].str.contains(themes_regex, case=False, na=False, regex=True)]\n",
    "\n",
    "            # Save the filtered data as a JSON file\n",
    "            output_json_file = f'output_{day_str}.json'\n",
    "            df.to_json(output_json_file, orient='records')\n",
    "            print(f'Saved filtered data for {day_str} to {output_json_file}')\n",
    "\n",
    "            # Append the filtered data to the merged_data list\n",
    "            merged_data.extend(df.to_dict(orient='records'))\n",
    "\n",
    "        # Save the merged and filtered data as a single JSON file\n",
    "        with open(output_file_path, \"w\") as output_file:\n",
    "            json.dump(merged_data, output_file)\n",
    "\n",
    "        print(f\"Merged and filtered data saved to {output_file_path}\")\n",
    "\n",
    "        # Delete individual filtered files\n",
    "        for day in past_dates + succeeding_dates:\n",
    "            day_str = day.replace(\"/\", \"\")\n",
    "            output_json_file = f'output_{day_str}.json'\n",
    "            if os.path.exists(output_json_file):\n",
    "                os.remove(output_json_file)\n",
    "\n",
    "        print(\"Individual filtered files deleted.\")\n",
    "\n",
    "    except ValueError:\n",
    "        print(\"Invalid date format. Please use 'dd/mm/yyyy'.\")\n",
    "\n",
    "# Example usage:\n",
    "output_file_path = 'gdelt_benin.json'\n",
    "input_date = \"14/07/2017\"\n",
    "locations_regex = 'Benin|Nigeria'  # Adjust the regex pattern as needed\n",
    "themes_regex = 'HUMAN_RIGHTS|HUMAN_RIGHTS_'  # Adjust the regex pattern as needed\n",
    "download_and_filter_gdelt_data(output_file_path, input_date, locations_regex, themes_regex)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
